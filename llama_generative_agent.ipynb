{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp, GPT4All\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# local_path = \"/Users/jon/Downloads/ggml-vicuna-13b-1.1-q4_2.bin\"\n",
    "# llm = LlamaCpp(model_path=local_path, verbose=True, use_mmap=False, n_ctx=2048)\n",
    "\n",
    "local_path = \"/Users/jon/Downloads/gpt4all-lora-unfiltered-quantized.bin\"\n",
    "llm = GPT4All(model=local_path, n_ctx=2048)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USER_NAME = \"Jon\" # The name you want to use when interviewing the agent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from retrivers.llama_time_weighted_retriever import LlamaTimeWeightedVectorStoreRetriever\n",
    "from vectorestores.chroma import EnhancedChroma\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    embeddings_model = LlamaCppEmbeddings(model_path=local_path)\n",
    "    vs = EnhancedChroma(embedding_function=embeddings_model)\n",
    "    return LlamaTimeWeightedVectorStoreRetriever(vectorstore=vs, other_score_keys=[\"importance\"], k=15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from generative_agents.llama_generative_agent import LlamaGenerativeAgent\n",
    "from generative_agents.llama_memory import LlamaGenerativeAgentMemory\n",
    "\n",
    "tommies_memory = LlamaGenerativeAgentMemory(\n",
    "    llm=llm,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    reflection_threshold=8, # we will give this a relatively low number to show how reflection works\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "tommie = LlamaGenerativeAgent(\n",
    "    name=\"Tommie\",\n",
    "    age=25,\n",
    "    traits=\"anxious, likes design, talkative\", # You can add more persistent traits here\n",
    "    status=\"looking for a job\", # When connected to a virtual world, we can have the characters update their status\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    llm=llm,\n",
    "    memory=tommies_memory,\n",
    "    verbose=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(tommie.get_summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We can add memories directly to the memory object\n",
    "tommie_observations = [\n",
    "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
    "    \"Tommie feels tired from driving so far\",\n",
    "    \"Tommie sees the new home\",\n",
    "    \"The new neighbors have a cat\",\n",
    "    \"The road is noisy at night\",\n",
    "    \"Tommie is hungry\",\n",
    "    \"Tommie tries to get some rest.\",\n",
    "]\n",
    "for observation in tommie_observations:\n",
    "    tommie.memory.add_memory(observation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now that Tommie has 'memories', their self-summary is more descriptive, though still rudimentary.\n",
    "# We will see how this summary updates after more observations to create a more rich description.\n",
    "print(tommie.get_summary(force_refresh=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def interview_agent(agent: LlamaGenerativeAgent, message: str) -> str:\n",
    "    \"\"\"Help the notebook user interact with the agent.\"\"\"\n",
    "    new_message = f\"{USER_NAME} says {message}\"\n",
    "    return agent.generate_dialogue_response(new_message)[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interview_agent(tommie, \"What are you most worried about today?\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# interview_agent(tommie, \"What are you looking forward to doing today?\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# interview_agent(tommie, \"What are you most worried about today?\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# interview_agent(tommie, \"Are you in love?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
